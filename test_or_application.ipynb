{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm -r ./*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'scratch_detection'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Flex-Group/scratch_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip scratch_detection/mrcnn.zip\n",
    "!unzip scratch_detection/logs.zip\n",
    "!unzip scratch_detection/scratch_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp scratch_dataset -r scratch_detection/\n",
    "!cp logs -r scratch_detection/\n",
    "!cp mrcnn scratch_deteaction/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==1.14.0\n",
    "!pip install keras==2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import skimage\n",
    "import glob\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  \n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "\n",
    "from scratch_detection import scratch_model\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/Phumudzo-git/car_damage/releases/download/v1/model_weights_0030.h5\n",
    "custom_WEIGHTS_PATH = \"model_weights_0030.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = scratch_model.CustomConfig()\n",
    "custom_DIR = os.path.join(ROOT_DIR, \"scratch_detection/scratch_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override the training configurations with a few\n",
    "# changes for inferencing.\n",
    "class InferenceConfig(config.__class__):\n",
    "    # Run detection on one image at a time\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device to load the neural network on.\n",
    "# machine, in which case use CPU and leave the\n",
    "# GPU for training.\n",
    "DEVICE = \"/cpu:0\"  # /cpu:0 or /gpu:0\n",
    "\n",
    "# Inspect the model in training or inference modes\n",
    "# values: 'inference' or 'training'\n",
    "# TODO: code for 'training' test mode not ready yet\n",
    "TEST_MODE = \"inference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=16):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Adjust the size attribute to control how big to render images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = scratch_model.CustomDataset()\n",
    "dataset.load_custom(custom_DIR, \"val\")\n",
    "\n",
    "# prepare the dataset\n",
    "dataset.prepare()\n",
    "\n",
    "print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model in inference mode\n",
    "with tf.device(DEVICE):\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR,\n",
    "                              config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the last model you trained\n",
    "# weights_path = model.find_last()[1]\n",
    "\n",
    "# Load weights\n",
    "print(\"Loading weights \", custom_WEIGHTS_PATH)\n",
    "model.load_weights(custom_WEIGHTS_PATH, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test or application of the model from the uploaded images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload # was constantly changin the visualization, so I decided to reload it instead of notebook\n",
    "reload(visualize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = random.choice(dataset.image_ids)\n",
    "image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)\n",
    "info = dataset.image_info[image_id]\n",
    "print(\"image ID: {}.{} ({}) {}\".format(info[\"source\"], info[\"id\"], image_id, \n",
    "                                       dataset.image_reference(image_id)))\n",
    "\n",
    "# Run object detection\n",
    "results = model.detect([image], verbose=1)\n",
    "\n",
    "# Display results\n",
    "ax = get_ax(1)\n",
    "r = results[0]\n",
    "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset.class_names, r['scores'], ax=ax,\n",
    "                            title=\"Predictions\")\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test or application of the model from taking a real-time video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Javascript\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode\n",
    "\n",
    "def take_photo(filename='photo.jpg', quality=0.8):\n",
    "    js = Javascript('''\n",
    "        async function takePhoto(quality) {\n",
    "            const div = document.createElement('div');\n",
    "            const video = document.createElement('video');\n",
    "            video.style.display = 'block';\n",
    "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
    "\n",
    "            // show the video in the HTML element\n",
    "            document.body.appendChild(div);\n",
    "            div.appendChild(video);\n",
    "            video.srcObject = stream;\n",
    "            await video.play();\n",
    "\n",
    "            // Resize the output to fit the video element.\n",
    "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
    "\n",
    "            // prints the logs to cell\n",
    "            let jsLog = function(abc) {\n",
    "            document.querySelector(\"#output-area\").appendChild(document.createTextNode(`${abc}... `));\n",
    "            }\n",
    "\n",
    "      // Wait for Capture to be clicked.\n",
    "      // await new Promise((resolve) => capture.onclick = resolve);\n",
    "\n",
    "      for (let i = 0; i < 5; i++) {\n",
    "        const canvas = document.createElement('canvas');\n",
    "        canvas.width = video.videoWidth;\n",
    "        canvas.height = video.videoHeight;\n",
    "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
    "        img = canvas.toDataURL('image/jpeg', quality);\n",
    "\n",
    "        // show each captured image\n",
    "        // let imgTag = document.createElement('img');\n",
    "        // imgTag.src = img;\n",
    "        // div.appendChild(imgTag);\n",
    "\n",
    "        jsLog(i + \"sending\")\n",
    "        // Call a python function and send this image\n",
    "        google.colab.kernel.invokeFunction('notebook.run_algo', [img], {});\n",
    "        jsLog(i + \"SENT\")\n",
    "\n",
    "        // wait for X miliseconds second, before next capture\n",
    "        await new Promise(resolve => setTimeout(resolve, 250));\n",
    "      }\n",
    "\n",
    "      stream.getVideoTracks()[0].stop(); // stop video stream\n",
    "    }\n",
    "    ''')\n",
    "    display(js) # make the provided HTML, part of the cell\n",
    "    data = eval_js('takePhoto({})'.format(quality)) # call the takePhoto() JavaScript function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "from google.colab import output\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import logging\n",
    "\n",
    "def data_uri_to_img(uri):\n",
    "  \"\"\"convert base64image to numpy array\"\"\"\n",
    "  try:\n",
    "    image = base64.b64decode(uri.split(',')[1], validate=True)\n",
    "    # make the binary image, a PIL image\n",
    "    image = Image.open(BytesIO(image))\n",
    "    # convert to numpy array\n",
    "    image = np.array(image, dtype=np.uint8); \n",
    "    return image\n",
    "  except Exception as e:\n",
    "    logging.exception(e);print('\\n')\n",
    "    return None\n",
    "\n",
    "def run_algo(imgB64):\n",
    "    \"\"\"\n",
    "    in Colab, run_algo function gets invoked by the JavaScript, that sends N images every second\n",
    "\n",
    "    params:\n",
    "    image: image\n",
    "    \"\"\"\n",
    "    image = data_uri_to_img(imgB64)  \n",
    "    if image is None:\n",
    "        print(\"At run_algo(): image is None.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Run detection\n",
    "        results = model.detect([image], verbose=1)\n",
    "        # Visualize results\n",
    "        r = results[0]\n",
    "        visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], class_names, r['scores'])\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.exception(e)\n",
    "        print('\\n')\n",
    "\n",
    "# register this function, so JS code could call this\n",
    "output.register_callback('notebook.run_algo', run_algo)\n",
    "\n",
    "# put the JS code in cell and run it\n",
    "#take_photo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['BG', 'damage']\n",
    "take_photo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
